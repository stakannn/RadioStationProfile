{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8528460,"sourceType":"datasetVersion","datasetId":5093126}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"for epoch in range(5):\n    for i, (features, labels) in enumerate(train_dataloader):\n        outputs = model(features)\n        loss = F.cross_entropy(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport os\nfrom pydub import AudioSegment\nimport numpy as np\nimport math\nfrom scipy.io.wavfile import read\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T13:19:54.198152Z","iopub.execute_input":"2024-05-27T13:19:54.199362Z","iopub.status.idle":"2024-05-27T13:19:54.205420Z","shell.execute_reply.started":"2024-05-27T13:19:54.199300Z","shell.execute_reply":"2024-05-27T13:19:54.204099Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sampling_rate = 22050 # Hz\nframe_length = 256 # samples\nhop_length = 128 # samples\nwindow_length = 172 # frames","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:28.666758Z","iopub.execute_input":"2024-05-27T13:07:28.667161Z","iopub.status.idle":"2024-05-27T13:07:28.672299Z","shell.execute_reply.started":"2024-05-27T13:07:28.667133Z","shell.execute_reply":"2024-05-27T13:07:28.671195Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def framing(signal, frame_length=frame_length, hop_length=hop_length):\n    n_frames = int((len(signal) - frame_length) / hop_length + 1)\n    frames =[]\n    for i in range(n_frames):\n        frame = signal[i * hop_length : i * hop_length + frame_length]\n        frames.append(frame)\n    return frames","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:29.806937Z","iopub.execute_input":"2024-05-27T13:07:29.807660Z","iopub.status.idle":"2024-05-27T13:07:29.813917Z","shell.execute_reply.started":"2024-05-27T13:07:29.807625Z","shell.execute_reply":"2024-05-27T13:07:29.812851Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def windowing(frames, window_length):\n    n_windows = int(len(frames) / window_length)\n    windows = {}\n    for i in range(n_windows):\n        window = frames[i * window_length : i * window_length + window_length]\n        windows[i] = {'window_frames': window}\n    return windows","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:30.580255Z","iopub.execute_input":"2024-05-27T13:07:30.580678Z","iopub.status.idle":"2024-05-27T13:07:30.586920Z","shell.execute_reply.started":"2024-05-27T13:07:30.580647Z","shell.execute_reply":"2024-05-27T13:07:30.585778Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def normalize_STE(ste_s):\n    cl_win_STE = sum(ste_s)\n    norm_ste_s = []\n    for ste in ste_s:\n        norm_ste_s.append(ste / cl_win_STE)\n    return norm_ste_s","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:31.052820Z","iopub.execute_input":"2024-05-27T13:07:31.053179Z","iopub.status.idle":"2024-05-27T13:07:31.058585Z","shell.execute_reply.started":"2024-05-27T13:07:31.053153Z","shell.execute_reply":"2024-05-27T13:07:31.057496Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def STE_frame(windows):\n    normalized_frames_ste_s = []\n    for i, window in windows.items():\n        ste = np.zeros(len(window['window_frames']))\n        for j, frame in enumerate(window['window_frames']):\n            ste[j] = np.sum(frame**2)\n        norm_ste_s = normalize_STE(ste)\n        windows[i]['normalized_ste_s'] = norm_ste_s\n        normalized_frames_ste_s.extend(norm_ste_s)\n    return normalized_frames_ste_s","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:31.403668Z","iopub.execute_input":"2024-05-27T13:07:31.404724Z","iopub.status.idle":"2024-05-27T13:07:31.410932Z","shell.execute_reply.started":"2024-05-27T13:07:31.404687Z","shell.execute_reply":"2024-05-27T13:07:31.409776Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess(paths_to_pieces):\n    pieces = {}\n    for p in paths_to_pieces:\n        signal, sr = librosa.load(p, sr=sampling_rate)\n        pieces[p] = {'signal': signal[0:110250]}\n    for i, (piece_name, data) in enumerate(pieces.items()):\n        data['frames'] = framing(data['signal'])\n        data['windows'] = windowing(data['frames'], window_length)\n        data['normalized_frames_ste_s'] = STE_frame(data['windows'])\n        data['MED_s'] = []\n        for i, win in data['windows'].items():\n            win_MED = min(win['normalized_ste_s'])\n            win['MED'] = win_MED\n            data['MED_s'].append(win_MED)\n        if i % 1000 == 0:\n            print(i)\n    return [data['MED_s'] for data in pieces.values()]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:07:31.878802Z","iopub.execute_input":"2024-05-27T13:07:31.879792Z","iopub.status.idle":"2024-05-27T13:07:31.888963Z","shell.execute_reply.started":"2024-05-27T13:07:31.879744Z","shell.execute_reply":"2024-05-27T13:07:31.887668Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"speech_train_ds = {}\nfor name in os.listdir('/kaggle/input/train-n-test-datasets/speech_train'):\n    speech_train_ds[('/kaggle/input/train-n-test-datasets/speech_train/' + name)] = 1\n\nmusic_train_ds = {}\nfor name in os.listdir('/kaggle/input/train-n-test-datasets/music_train'):\n    music_train_ds[('/kaggle/input/train-n-test-datasets/music_train/' + name)] = 0\n\nspeech_test_ds = {}\nfor name in os.listdir('/kaggle/input/train-n-test-datasets/speech_test'):\n    speech_test_ds[('/kaggle/input/train-n-test-datasets/speech_test/' + name)] = 1\n\nmusic_test_ds = {}\nfor name in os.listdir('/kaggle/input/train-n-test-datasets/music_test'):\n    music_test_ds[('/kaggle/input/train-n-test-datasets/music_test/' + name)] = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:47:52.962227Z","iopub.execute_input":"2024-05-27T13:47:52.963380Z","iopub.status.idle":"2024-05-27T13:47:53.009619Z","shell.execute_reply.started":"2024-05-27T13:47:52.963344Z","shell.execute_reply":"2024-05-27T13:47:53.008486Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:47:45.358111Z","iopub.execute_input":"2024-05-27T13:47:45.358572Z","iopub.status.idle":"2024-05-27T13:47:47.339535Z","shell.execute_reply.started":"2024-05-27T13:47:45.358538Z","shell.execute_reply":"2024-05-27T13:47:47.338384Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"class AudioFeaturesDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:47:47.341939Z","iopub.execute_input":"2024-05-27T13:47:47.342897Z","iopub.status.idle":"2024-05-27T13:47:47.349143Z","shell.execute_reply.started":"2024-05-27T13:47:47.342856Z","shell.execute_reply":"2024-05-27T13:47:47.348069Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class AudioClassifier(nn.Module):\n    def __init__(self):\n        super(AudioClassifierCNN, self).__init__()\n        self.fc1 = nn.Linear(5, 400)\n        self.fc2 = nn.Linear(400, 800)\n        self.fc3 = nn.Linear(800, 2)\n        \n    def forward(self, x):\n        #x = F.relu(self.conv1(x))\n        #x = F.relu(self.conv2(x))\n        #x = F.max_pool1d(x, kernel_size=2)  # Pooling to reduce dimensionality\n        #x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.softmax(self.fc3(x), dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:30:37.112633Z","iopub.execute_input":"2024-05-27T14:30:37.113057Z","iopub.status.idle":"2024-05-27T14:30:37.121778Z","shell.execute_reply.started":"2024-05-27T14:30:37.113023Z","shell.execute_reply":"2024-05-27T14:30:37.120377Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"len(speech_train_ds), len(music_train_ds), len(speech_test_ds), len(music_test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:32:33.405942Z","iopub.execute_input":"2024-05-27T14:32:33.406447Z","iopub.status.idle":"2024-05-27T14:32:33.414768Z","shell.execute_reply.started":"2024-05-27T14:32:33.406411Z","shell.execute_reply":"2024-05-27T14:32:33.413560Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"(13000, 10001, 2500, 2002)"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = {**music_train_ds, **speech_train_ds}\ntest_ds = {**music_test_ds, **speech_test_ds}\nlen(train_ds), len(test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:47:56.279460Z","iopub.execute_input":"2024-05-27T13:47:56.279876Z","iopub.status.idle":"2024-05-27T13:47:56.291234Z","shell.execute_reply.started":"2024-05-27T13:47:56.279844Z","shell.execute_reply":"2024-05-27T13:47:56.290050Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"(23001, 4502)"},"metadata":{}}]},{"cell_type":"code","source":"train_features = [torch.Tensor(smpl) for smpl in preprocess(list(train_ds.keys()))]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:48:02.176265Z","iopub.execute_input":"2024-05-27T13:48:02.177264Z","iopub.status.idle":"2024-05-27T13:58:59.506772Z","shell.execute_reply.started":"2024-05-27T13:48:02.177222Z","shell.execute_reply":"2024-05-27T13:58:59.505485Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2123222298.py:5: RuntimeWarning: invalid value encountered in scalar divide\n  norm_ste_s.append(ste / cl_win_STE)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels = torch.tensor(list(train_ds.values()), dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:58:59.508779Z","iopub.execute_input":"2024-05-27T13:58:59.509111Z","iopub.status.idle":"2024-05-27T13:58:59.520560Z","shell.execute_reply.started":"2024-05-27T13:58:59.509083Z","shell.execute_reply":"2024-05-27T13:58:59.519573Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"len(train_features), len(train_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:32:53.669301Z","iopub.execute_input":"2024-05-27T14:32:53.670525Z","iopub.status.idle":"2024-05-27T14:32:53.678791Z","shell.execute_reply.started":"2024-05-27T14:32:53.670475Z","shell.execute_reply":"2024-05-27T14:32:53.677593Z"},"trusted":true},"execution_count":160,"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"(23001, 23001)"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = AudioFeaturesDataset(train_features, train_labels)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:32:54.137851Z","iopub.execute_input":"2024-05-27T14:32:54.138275Z","iopub.status.idle":"2024-05-27T14:32:54.147001Z","shell.execute_reply.started":"2024-05-27T14:32:54.138243Z","shell.execute_reply":"2024-05-27T14:32:54.145706Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"class AudioClassifier(nn.Module):\n    def __init__(self):\n        super(AudioClassifier, self).__init__()\n        self.fc1 = nn.Linear(5, 400)\n        self.fc2 = nn.Linear(400, 800)\n        self.fc3 = nn.Linear(800, 2)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.softmax(self.fc3(x), dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:32:58.445517Z","iopub.execute_input":"2024-05-27T14:32:58.446460Z","iopub.status.idle":"2024-05-27T14:32:58.454004Z","shell.execute_reply.started":"2024-05-27T14:32:58.446420Z","shell.execute_reply":"2024-05-27T14:32:58.452697Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlearning_rate = 0.001\nbatch_size = 32\n\nmodel = AudioClassifier()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:33:00.676852Z","iopub.execute_input":"2024-05-27T14:33:00.677346Z","iopub.status.idle":"2024-05-27T14:33:00.689735Z","shell.execute_reply.started":"2024-05-27T14:33:00.677311Z","shell.execute_reply":"2024-05-27T14:33:00.688611Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    running_loss = 0.0\n    for i, (features, labels) in enumerate(train_dataloader):\n        outputs = model(features)\n\n        optimizer.zero_grad()\n\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 2000 == 1999:\n            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:33:03.286607Z","iopub.execute_input":"2024-05-27T14:33:03.287583Z","iopub.status.idle":"2024-05-27T14:33:32.369689Z","shell.execute_reply.started":"2024-05-27T14:33:03.287548Z","shell.execute_reply":"2024-05-27T14:33:32.368638Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stdout","text":"Finished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"test_features = [torch.Tensor(smpl) for smpl in preprocess(list(test_ds.keys()))]\ntest_labels = torch.tensor(list(test_ds.values()), dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:34:00.529488Z","iopub.execute_input":"2024-05-27T14:34:00.529913Z","iopub.status.idle":"2024-05-27T14:36:22.902871Z","shell.execute_reply.started":"2024-05-27T14:34:00.529880Z","shell.execute_reply":"2024-05-27T14:36:22.901422Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"test_dataset = AudioFeaturesDataset(test_features, test_labels)\ntest_dataloader = DataLoader(test_dataset, batch_size=32)\n\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for features, labels in test_dataloader:\n        outputs = model(features)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:36:22.905827Z","iopub.execute_input":"2024-05-27T14:36:22.906375Z","iopub.status.idle":"2024-05-27T14:36:23.039275Z","shell.execute_reply.started":"2024-05-27T14:36:22.906330Z","shell.execute_reply":"2024-05-27T14:36:23.038153Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy of the network on the test dataset: {100 * correct / total} %')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:36:23.040916Z","iopub.execute_input":"2024-05-27T14:36:23.041584Z","iopub.status.idle":"2024-05-27T14:36:23.047806Z","shell.execute_reply.started":"2024-05-27T14:36:23.041535Z","shell.execute_reply":"2024-05-27T14:36:23.046857Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"Accuracy of the network on the test dataset: 44.46912483340738 %\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'audio_classifier.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:40:13.534038Z","iopub.execute_input":"2024-05-27T14:40:13.536092Z","iopub.status.idle":"2024-05-27T14:40:13.549262Z","shell.execute_reply.started":"2024-05-27T14:40:13.535927Z","shell.execute_reply":"2024-05-27T14:40:13.547221Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:39:26.782073Z","iopub.status.idle":"2024-05-25T20:39:26.782684Z","shell.execute_reply.started":"2024-05-25T20:39:26.782501Z","shell.execute_reply":"2024-05-25T20:39:26.782519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}